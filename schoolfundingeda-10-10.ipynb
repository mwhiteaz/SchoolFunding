{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9596484,"sourceType":"datasetVersion","datasetId":5853922}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T23:55:13.238143Z","iopub.execute_input":"2025-02-25T23:55:13.238549Z","iopub.status.idle":"2025-02-25T23:55:16.149536Z","shell.execute_reply.started":"2025-02-25T23:55:13.238496Z","shell.execute_reply":"2025-02-25T23:55:16.148377Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install openpyxl  # For reading .xlsx files\n!pip install pyxlsb","metadata":{"execution":{"iopub.status.busy":"2025-02-25T23:58:53.760809Z","iopub.execute_input":"2025-02-25T23:58:53.761679Z","iopub.status.idle":"2025-02-25T23:59:15.362539Z","shell.execute_reply.started":"2025-02-25T23:58:53.761635Z","shell.execute_reply":"2025-02-25T23:59:15.361282Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.5)\nRequirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\nCollecting pyxlsb\n  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl.metadata (2.5 kB)\nDownloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\nInstalling collected packages: pyxlsb\nSuccessfully installed pyxlsb-1.0.10\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Load my file\nfile_path = '/kaggle/input/fundingdf/DistrictCostDatabase_2024 (1).xlsb'  \ndf = pd.read_excel(file_path, engine='pyxlsb')\n\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2025-02-25T23:59:25.149246Z","iopub.execute_input":"2025-02-25T23:59:25.149674Z","iopub.status.idle":"2025-02-25T23:59:56.282469Z","shell.execute_reply.started":"2025-02-25T23:59:25.149632Z","shell.execute_reply":"2025-02-25T23:59:56.281434Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   year   leaid          district state_name stabbr  ppcstot  predcost  \\\n0  2009  100005  ALBERTVILLE CITY    Alabama     AL     8608     12557   \n1  2010  100005  ALBERTVILLE CITY    Alabama     AL     8688     12567   \n2  2011  100005  ALBERTVILLE CITY    Alabama     AL     8492     11509   \n3  2012  100005  ALBERTVILLE CITY    Alabama     AL     8157     15540   \n4  2013  100005  ALBERTVILLE CITY    Alabama     AL     8069     14412   \n\n   fundinggap  outcomegap  enroll       pov       iep       ell     amind  \\\n0       -3949   -0.373566    3849  0.302567  0.009353  0.204729  0.001823   \n1       -3879   -0.216288    4104  0.334258  0.074561  0.197856  0.001467   \n2       -3017   -0.190391    4143  0.339477  0.063481  0.144340  0.000483   \n3       -7383   -0.117687    4140  0.444417  0.075604  0.143720  0.001208   \n4       -6343   -0.278603    4422  0.389776  0.071009  0.160271  0.001583   \n\n      asian     black      hisp     multi       pac     white  \n0  0.004427  0.022917  0.317188       NaN       NaN  0.653646  \n1  0.005136  0.022010  0.335534       NaN       NaN  0.635852  \n2  0.003138  0.022930  0.351195  0.000965  0.000000  0.621289  \n3  0.002657  0.017874  0.349758  0.011836  0.000000  0.616667  \n4  0.002714  0.017413  0.378109  0.017187  0.000226  0.582768  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Get a quick summary of the dataframe\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2025-02-26T00:00:06.758654Z","iopub.execute_input":"2025-02-26T00:00:06.759204Z","iopub.status.idle":"2025-02-26T00:00:06.822049Z","shell.execute_reply.started":"2025-02-26T00:00:06.759153Z","shell.execute_reply":"2025-02-26T00:00:06.820744Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159034 entries, 0 to 159033\nData columns (total 20 columns):\n #   Column      Non-Null Count   Dtype  \n---  ------      --------------   -----  \n 0   year        159034 non-null  int64  \n 1   leaid       159034 non-null  int64  \n 2   district    159034 non-null  object \n 3   state_name  159034 non-null  object \n 4   stabbr      159034 non-null  object \n 5   ppcstot     159034 non-null  int64  \n 6   predcost    159034 non-null  int64  \n 7   fundinggap  159034 non-null  int64  \n 8   outcomegap  113880 non-null  float64\n 9   enroll      159034 non-null  int64  \n 10  pov         159034 non-null  float64\n 11  iep         155023 non-null  float64\n 12  ell         157748 non-null  float64\n 13  amind       159034 non-null  float64\n 14  asian       159034 non-null  float64\n 15  black       159034 non-null  float64\n 16  hisp        159034 non-null  float64\n 17  multi       139366 non-null  float64\n 18  pac         136863 non-null  float64\n 19  white       159034 non-null  float64\ndtypes: float64(11), int64(6), object(3)\nmemory usage: 24.3+ MB\nNone\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(df.describe())","metadata":{"execution":{"iopub.status.busy":"2025-02-26T00:00:14.672164Z","iopub.execute_input":"2025-02-26T00:00:14.673098Z","iopub.status.idle":"2025-02-26T00:00:14.811922Z","shell.execute_reply.started":"2025-02-26T00:00:14.673057Z","shell.execute_reply":"2025-02-26T00:00:14.810892Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                year         leaid        ppcstot       predcost  \\\ncount  159034.000000  1.590340e+05  159034.000000  159034.000000   \nmean     2014.946370  3.012129e+06   12254.636625   11703.865570   \nstd         3.738836  1.470075e+06    4572.360238    6247.861275   \nmin      2009.000000  1.000050e+05     251.000000    3282.000000   \n25%      2012.000000  1.808010e+06    9216.000000    7991.000000   \n50%      2015.000000  3.028911e+06   10931.000000   10098.000000   \n75%      2018.000000  4.104590e+06   13981.000000   13305.750000   \nmax      2021.000000  5.606240e+06  130849.000000   94853.000000   \n\n          fundinggap     outcomegap        enroll            pov  \\\ncount  159034.000000  113880.000000  1.590340e+05  159034.000000   \nmean      550.772099       0.024527  3.861922e+03       0.172366   \nstd      7433.439068       0.353197  1.518221e+04       0.095372   \nmin    -85859.000000      -3.797798  1.000000e+02       0.000000   \n25%     -2412.000000      -0.194640  5.120000e+02       0.099757   \n50%       815.000000       0.025832  1.270000e+03       0.157593   \n75%      3941.000000       0.240322  3.214000e+03       0.228721   \nmax    122599.000000       1.657541  1.014020e+06       1.000000   \n\n                 iep            ell          amind          asian  \\\ncount  155023.000000  157748.000000  159034.000000  159034.000000   \nmean        0.143122       0.047797       0.025635       0.021349   \nstd         0.046250       0.088994       0.102458       0.049863   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.113218       0.002149       0.000571       0.002282   \n50%         0.139737       0.012428       0.002486       0.006692   \n75%         0.169299       0.049331       0.007117       0.017425   \nmax         0.996670       0.956740       1.000000       0.747499   \n\n               black           hisp          multi            pac  \\\ncount  159034.000000  159034.000000  139366.000000  136863.000000   \nmean        0.072368       0.141924       0.029507       0.001431   \nstd         0.155590       0.205301       0.034307       0.004357   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.005435       0.020537       0.008822       0.000000   \n50%         0.013889       0.052871       0.021472       0.000166   \n75%         0.050059       0.160795       0.039073       0.001421   \nmax         1.000000       1.000000       0.990291       0.267496   \n\n               white  \ncount  159034.000000  \nmean        0.711635  \nstd         0.272841  \nmin         0.000000  \n25%         0.559958  \n50%         0.820104  \n75%         0.927711  \nmax         1.000000  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2025-02-18T17:38:59.637365Z","iopub.execute_input":"2025-02-18T17:38:59.638324Z","iopub.status.idle":"2025-02-18T17:38:59.673161Z","shell.execute_reply.started":"2025-02-18T17:38:59.638268Z","shell.execute_reply":"2025-02-18T17:38:59.672153Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot histogram to inspect the distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(df['outcomegap'], kde=True)  # kde=True adds a kernel density estimate (smooth curve)\nplt.title('Distribution of Outcome Gap')\nplt.xlabel('Gap Measure')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:00:34.180461Z","iopub.execute_input":"2025-02-07T17:00:34.181082Z","iopub.status.idle":"2025-02-07T17:00:35.750971Z","shell.execute_reply.started":"2025-02-07T17:00:34.181016Z","shell.execute_reply":"2025-02-07T17:00:35.749885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot histogram to inspect the distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(df['multi'], kde=True)  # kde=True adds a kernel density estimate (smooth curve)\nplt.title('Distribution of Multi race')\nplt.xlabel('% of Multirace students')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:02:28.203931Z","iopub.execute_input":"2025-02-07T17:02:28.204379Z","iopub.status.idle":"2025-02-07T17:02:30.483952Z","shell.execute_reply.started":"2025-02-07T17:02:28.204340Z","shell.execute_reply":"2025-02-07T17:02:30.482509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot histogram to inspect the distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(df['pac'], kde=True)  # kde=True adds a kernel density estimate (smooth curve)\nplt.title('Distribution of Pac students')\nplt.xlabel('% of Pac students')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:02:53.054607Z","iopub.execute_input":"2025-02-07T17:02:53.055433Z","iopub.status.idle":"2025-02-07T17:03:00.907592Z","shell.execute_reply.started":"2025-02-07T17:02:53.055355Z","shell.execute_reply":"2025-02-07T17:03:00.906312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot histogram to inspect the distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(df['iep'], kde=True)  # kde=True adds a kernel density estimate (smooth curve)\nplt.title('Distribution of iep students')\nplt.xlabel('% of iep students')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:04:17.040447Z","iopub.execute_input":"2025-02-07T17:04:17.040925Z","iopub.status.idle":"2025-02-07T17:04:18.708312Z","shell.execute_reply.started":"2025-02-07T17:04:17.040885Z","shell.execute_reply":"2025-02-07T17:04:18.707176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot histogram to inspect the distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(df['ell'], kde=True)  # kde=True adds a kernel density estimate (smooth curve)\nplt.title('Distribution of ell students')\nplt.xlabel('% of ell students')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:04:30.591658Z","iopub.execute_input":"2025-02-07T17:04:30.592222Z","iopub.status.idle":"2025-02-07T17:04:32.647702Z","shell.execute_reply.started":"2025-02-07T17:04:30.592177Z","shell.execute_reply":"2025-02-07T17:04:32.646339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Impute with the mean for numerical variables\ndf[['outcomegap', 'iep']] = df[['outcomegap', 'iep']].apply(lambda x: x.fillna(x.mean()))","metadata":{"execution":{"iopub.status.busy":"2025-02-26T00:00:34.704166Z","iopub.execute_input":"2025-02-26T00:00:34.704626Z","iopub.status.idle":"2025-02-26T00:00:34.718185Z","shell.execute_reply.started":"2025-02-26T00:00:34.704538Z","shell.execute_reply":"2025-02-26T00:00:34.717231Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Impute with the mode for numerical variables\ndf[['multi', 'pac', 'ell']] = df[['multi', 'pac', 'ell']].apply(lambda x: x.fillna(x.mode()[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T00:00:41.961448Z","iopub.execute_input":"2025-02-26T00:00:41.961837Z","iopub.status.idle":"2025-02-26T00:00:42.000858Z","shell.execute_reply.started":"2025-02-26T00:00:41.961804Z","shell.execute_reply":"2025-02-26T00:00:41.999952Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T00:01:43.852286Z","iopub.execute_input":"2025-02-26T00:01:43.852733Z","iopub.status.idle":"2025-02-26T00:01:43.888352Z","shell.execute_reply.started":"2025-02-26T00:01:43.852663Z","shell.execute_reply":"2025-02-26T00:01:43.886951Z"}},"outputs":[{"name":"stdout","text":"year          0\nleaid         0\ndistrict      0\nstate_name    0\nstabbr        0\nppcstot       0\npredcost      0\nfundinggap    0\noutcomegap    0\nenroll        0\npov           0\niep           0\nell           0\namind         0\nasian         0\nblack         0\nhisp          0\nmulti         0\npac           0\nwhite         0\ndtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Select only numerical columns\nnumerical_df = df.select_dtypes(include=['number'])\n\n# Calculate correlations between numerical columns\ncorrelation_matrix = numerical_df.corr()\n\n# Visualize correlation matrix using a heatmap\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title(\"Correlation Matrix of Numerical Variables\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:39:35.666122Z","iopub.execute_input":"2025-02-18T17:39:35.666567Z","iopub.status.idle":"2025-02-18T17:39:36.892023Z","shell.execute_reply.started":"2025-02-18T17:39:35.666531Z","shell.execute_reply":"2025-02-18T17:39:36.890778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot actual spending per pupil, required spending per pupil, and the gap over years\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x='year', y='ppcstot', label='Actual Spending')\nsns.lineplot(data=df, x='year', y='fundinggap', label='Funding gap')\nplt.title('Trends in Actual, Required Spending, and Spending Gap (2009-2021)')\nplt.xlabel('Year')\nplt.ylabel('Spending per Pupil')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:39:52.234412Z","iopub.execute_input":"2025-02-18T17:39:52.234818Z","iopub.status.idle":"2025-02-18T17:39:55.513929Z","shell.execute_reply.started":"2025-02-18T17:39:52.234784Z","shell.execute_reply":"2025-02-18T17:39:55.511842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot demographic breakdown (e.g., percentage of Black, Hispanic students)\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x='year', y='black', label='Black Students')\nsns.lineplot(data=df, x='year', y='hisp', label='Hispanic Students')\nsns.lineplot(data=df, x='year', y='white', label='White Students')\nsns.lineplot(data=df, x='year', y='pov', label='Students in poverty')\nplt.title('Demographic Changes Over Time')\nplt.xlabel('Year')\nplt.ylabel('Percentage of Students')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:40:06.780113Z","iopub.execute_input":"2025-02-18T17:40:06.780551Z","iopub.status.idle":"2025-02-18T17:40:12.489479Z","shell.execute_reply.started":"2025-02-18T17:40:06.780508Z","shell.execute_reply":"2025-02-18T17:40:12.488300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot boxplot for percent special education students over the years\nplt.figure(figsize=(12, 6))\nsns.boxplot(data=df, x='year', y='iep')\nplt.title('Distribution of Special Education Students Over Time')\nplt.xlabel('Year')\nplt.ylabel('Percent of Special Education Students')\nplt.show()\n\n# Plot boxplot for percent ELL students over the years\nplt.figure(figsize=(12, 6))\nsns.boxplot(data=df, x='year', y='ell')\nplt.title('Distribution of ELL Students Over Time')\nplt.xlabel('Year')\nplt.ylabel('Percent of ELL Students')\nplt.show()\n\n# Plot boxplot for child poverty rate over the years\nplt.figure(figsize=(12, 6))\nsns.boxplot(data=df, x='year', y='pov')\nplt.title('Distribution of Child Poverty Rate Over Time')\nplt.xlabel('Year')\nplt.ylabel('Child Poverty Rate')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:41:02.191300Z","iopub.execute_input":"2025-02-18T17:41:02.192352Z","iopub.status.idle":"2025-02-18T17:41:03.528232Z","shell.execute_reply.started":"2025-02-18T17:41:02.192303Z","shell.execute_reply":"2025-02-18T17:41:03.526880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot total student enrollment over time\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x='year', y='enroll', color='purple')\nplt.title('Total Student Enrollment Over Time')\nplt.xlabel('Year')\nplt.ylabel('Total Enrollment')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:41:15.727179Z","iopub.execute_input":"2025-02-18T17:41:15.727760Z","iopub.status.idle":"2025-02-18T17:41:17.373889Z","shell.execute_reply.started":"2025-02-18T17:41:15.727706Z","shell.execute_reply":"2025-02-18T17:41:17.372628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select a subset of columns to visualize relationships\nsubset_df = df[['year', 'fundinggap','iep','pov','ell','black','hisp']]\n\n# Pairplot\nsns.pairplot(subset_df, diag_kind='kde', plot_kws={'alpha': 0.5})\nplt.suptitle('Pairplot of Selected Variables', y=1.02)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:43:53.172015Z","iopub.execute_input":"2025-02-07T17:43:53.172436Z","iopub.status.idle":"2025-02-07T17:44:26.841637Z","shell.execute_reply.started":"2025-02-07T17:43:53.172400Z","shell.execute_reply":"2025-02-07T17:44:26.840179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This code creates a function that produces a new column to identify the racial majority of a School District\n\ndef majority_minority(row):\n\n  \"\"\"\n\n  This function will check which racial grouping, White/Asian or Black/Hispanic/American Indian, \n\n  comprises over 50% of the student population\n\n  \"\"\"\n\n  # Combine percentages for White/Asian and URM groups\n\n  white_asian_percentage = row['white'] + row['asian']\n\n  minority_percentage = row['black'] + row['hisp'] + row['amind']+ row['multi']+ row['pac']\n\n  \n\n  if white_asian_percentage > 0.50:\n\n      return \"White/Asian Majority\"\n\n  elif minority_percentage > 0.50:\n\n      return \"URM Majority\"\n\n  else:\n\n      return \"Mixed\"\n\n \n\n# Run the function to create the new column\n\ndf['Majority_Group'] = df.apply(majority_minority, axis=1)\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:46:33.565582Z","iopub.execute_input":"2024-10-28T04:46:33.566056Z","iopub.status.idle":"2024-10-28T04:46:40.580860Z","shell.execute_reply.started":"2024-10-28T04:46:33.566010Z","shell.execute_reply":"2024-10-28T04:46:40.579405Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"state_to_region = {\n    'Alabama': 'South',\n    'Alaska': 'West',\n    'Arizona': 'West',\n    'Arkansas': 'South',\n    'California': 'West',\n    'Colorado': 'West',\n    'Connecticut': 'Northeast',\n    'Delaware': 'Northeast',\n    'Florida': 'South',\n    'Georgia': 'South',\n    'Hawaii': 'West',\n    'Idaho': 'West',\n    'Illinois': 'Midwest',\n    'Indiana': 'Midwest',\n    'Iowa': 'Midwest',\n    'Kansas': 'Midwest',\n    'Kentucky': 'South',\n    'Louisiana': 'South',\n    'Maine': 'Northeast',\n    'Maryland': 'Northeast',\n    'Massachusetts': 'Northeast',\n    'Michigan': 'Midwest',\n    'Minnesota': 'Midwest',\n    'Mississippi': 'South',\n    'Missouri': 'Midwest',\n    'Montana': 'West',\n    'Nebraska': 'Midwest',\n    'Nevada': 'West',\n    'New Hampshire': 'Northeast',\n    'New Jersey': 'Northeast',\n    'New Mexico': 'West',\n    'New York': 'Northeast',\n    'North Carolina': 'South',\n    'North Dakota': 'Midwest',\n    'Ohio': 'Midwest',\n    'Oklahoma': 'South',\n    'Oregon': 'West',\n    'Pennsylvania': 'Northeast',\n    'Rhode Island': 'Northeast',\n    'South Carolina': 'South',\n    'South Dakota': 'Midwest',\n    'Tennessee': 'South',\n    'Texas': 'South',\n    'Utah': 'West',\n    'Vermont': 'Northeast',\n    'Virginia': 'South',\n    'Washington': 'West',\n    'West Virginia': 'South',\n    'Wisconsin': 'Midwest',\n    'Wyoming': 'West'\n}\n\n# Create a new column for regions\ndf['Region'] = df['state_name'].map(state_to_region)\n\n# Display the updated DataFrame\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2025-02-26T00:05:30.199219Z","iopub.execute_input":"2025-02-26T00:05:30.199700Z","iopub.status.idle":"2025-02-26T00:05:30.268141Z","shell.execute_reply.started":"2025-02-26T00:05:30.199644Z","shell.execute_reply":"2025-02-26T00:05:30.266942Z"},"trusted":true},"outputs":[{"name":"stdout","text":"        year    leaid                          district state_name stabbr  \\\n0       2009   100005                  ALBERTVILLE CITY    Alabama     AL   \n1       2010   100005                  ALBERTVILLE CITY    Alabama     AL   \n2       2011   100005                  ALBERTVILLE CITY    Alabama     AL   \n3       2012   100005                  ALBERTVILLE CITY    Alabama     AL   \n4       2013   100005                  ALBERTVILLE CITY    Alabama     AL   \n...      ...      ...                               ...        ...    ...   \n159029  2017  5606090  WESTON COUNTY SCHOOL DISTRICT #7    Wyoming     WY   \n159030  2018  5606090  WESTON COUNTY SCHOOL DISTRICT #7    Wyoming     WY   \n159031  2019  5606090  WESTON COUNTY SCHOOL DISTRICT #7    Wyoming     WY   \n159032  2020  5606090  WESTON COUNTY SCHOOL DISTRICT #7    Wyoming     WY   \n159033  2021  5606090  WESTON COUNTY SCHOOL DISTRICT #7    Wyoming     WY   \n\n        ppcstot  predcost  fundinggap  outcomegap  enroll  ...       iep  \\\n0          8608     12557       -3949   -0.373566    3849  ...  0.009353   \n1          8688     12567       -3879   -0.216288    4104  ...  0.074561   \n2          8492     11509       -3017   -0.190391    4143  ...  0.063481   \n3          8157     15540       -7383   -0.117687    4140  ...  0.075604   \n4          8069     14412       -6343   -0.278603    4422  ...  0.071009   \n...         ...       ...         ...         ...     ...  ...       ...   \n159029    24186     10106       14080    0.518236     258  ...  0.139535   \n159030    22669     10883       11786    0.199631     254  ...  0.141732   \n159031    26525     11715       14810    0.053610     223  ...  0.165919   \n159032    26472     13563       12909    0.024527     235  ...  0.170213   \n159033    28640     12504       16136    0.024527     222  ...  0.143122   \n\n             ell     amind     asian     black      hisp     multi       pac  \\\n0       0.204729  0.001823  0.004427  0.022917  0.317188  0.000000  0.000000   \n1       0.197856  0.001467  0.005136  0.022010  0.335534  0.000000  0.000000   \n2       0.144340  0.000483  0.003138  0.022930  0.351195  0.000965  0.000000   \n3       0.143720  0.001208  0.002657  0.017874  0.349758  0.011836  0.000000   \n4       0.160271  0.001583  0.002714  0.017413  0.378109  0.017187  0.000226   \n...          ...       ...       ...       ...       ...       ...       ...   \n159029  0.005154  0.000000  0.000000  0.003876  0.034884  0.031008  0.000000   \n159030  0.011811  0.000000  0.000000  0.003937  0.023622  0.023622  0.000000   \n159031  0.013453  0.000000  0.000000  0.004484  0.026906  0.022422  0.000000   \n159032  0.012766  0.000000  0.000000  0.004255  0.025532  0.051064  0.000000   \n159033  0.013513  0.004504  0.000000  0.004504  0.013513  0.036036  0.000000   \n\n           white  Region  \n0       0.653646   South  \n1       0.635852   South  \n2       0.621289   South  \n3       0.616667   South  \n4       0.582768   South  \n...          ...     ...  \n159029  0.930233    West  \n159030  0.948819    West  \n159031  0.946188    West  \n159032  0.919149    West  \n159033  0.941441    West  \n\n[159034 rows x 21 columns]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a variable to filter the dataset by any year of interest\ndf_year = df[df['year'] == 2009]                    # Just like in section 1.3.1, you can use Boleans and comparison opperators to filter\n\n# We specify a size for our figure, and then construct a boxplot. Here we are looking at the\nplt.figure(figsize=(10, 15))                        # You can change the size\nsns.boxplot(data=df_year, x=\"fundinggap\", y=\"stabbr\")     # You can change the values of x and/or y for variables that interest you\n\n# Label our axes and title\nplt.xlabel(\"District funding gap levels\")\nplt.ylabel(\"State\")\nplt.title(\"Funding gap levels by State\")\n\n\n#Print the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-18T17:42:09.022604Z","iopub.execute_input":"2025-02-18T17:42:09.023010Z","iopub.status.idle":"2025-02-18T17:42:10.188403Z","shell.execute_reply.started":"2025-02-18T17:42:09.022973Z","shell.execute_reply":"2025-02-18T17:42:10.187050Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Aggregate funding data by State and Year (e.g., taking the mean)\nagg_df = df.groupby(['state_name', 'year'], as_index=False)['ppcstot'].mean()\n\n# Pivot the aggregated DataFrame for heatmap\npivot_df = agg_df.pivot(index='state_name', columns='year', values='ppcstot')\n\n# Create a heatmap\nplt.figure(figsize=(16, 12))\nsns.heatmap(pivot_df, annot=True, cmap='YlGnBu', fmt=\".0f\", cbar_kws={'label': 'Funding Levels'})\nplt.title('Funding Levels by State and Year')\nplt.xlabel('Year')\nplt.ylabel('State')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-18T17:42:59.702709Z","iopub.execute_input":"2025-02-18T17:42:59.703175Z","iopub.status.idle":"2025-02-18T17:43:02.138740Z","shell.execute_reply.started":"2025-02-18T17:42:59.703134Z","shell.execute_reply":"2025-02-18T17:43:02.137172Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Aggregate funding gaps by State and Year (e.g., taking the mean)\nagg_df = df.groupby(['state_name', 'year'], as_index=False)['fundinggap'].mean()\n\n# Pivot the aggregated DataFrame for heatmap\npivot_df = agg_df.pivot(index='state_name', columns='year', values='fundinggap')\n\n# Create a heatmap\nplt.figure(figsize=(16, 12))\nsns.heatmap(pivot_df, annot=True, cmap='YlGnBu', fmt=\".0f\", cbar_kws={'label': 'Funding Gaps'})\nplt.title('Funding Gaps by State and Year')\nplt.xlabel('Year')\nplt.ylabel('State')\n\n# Step 4: Save the figure as a PDF\nplt.savefig('visualization.pdf', format='pdf', bbox_inches='tight')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-18T17:43:15.090844Z","iopub.execute_input":"2025-02-18T17:43:15.091262Z","iopub.status.idle":"2025-02-18T17:43:20.272965Z","shell.execute_reply.started":"2025-02-18T17:43:15.091190Z","shell.execute_reply":"2025-02-18T17:43:20.271442Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# play with this to redo the colors\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Aggregate funding gaps by State and Year (e.g., taking the mean)\nagg_df = df.groupby(['state_name', 'year'], as_index=False)['fundinggap'].mean()\n\n# Pivot the aggregated DataFrame for heatmap\npivot_df = agg_df.pivot(index='state_name', columns='year', values='fundinggap')\n\n# Create a diverging color palette from skyblue to red\ncmap = sns.diverging_palette(200, 20, s=75, l=50, as_cmap=True)\n\n# Create a heatmap\nplt.figure(figsize=(16, 12))\nsns.heatmap(pivot_df, annot=True, cmap='YlGnBu', fmt=\".0f\", cbar_kws={'label': 'Funding Gaps'})\nplt.title('Funding Gaps by State and Year')\nplt.xlabel('Year')\nplt.ylabel('State')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T04:31:10.871169Z","iopub.execute_input":"2024-11-15T04:31:10.871682Z","iopub.status.idle":"2024-11-15T04:31:13.115205Z","shell.execute_reply.started":"2024-11-15T04:31:10.871636Z","shell.execute_reply":"2024-11-15T04:31:13.113906Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T00:03:15.262022Z","iopub.execute_input":"2025-02-26T00:03:15.262428Z","iopub.status.idle":"2025-02-26T00:03:15.751776Z","shell.execute_reply.started":"2025-02-26T00:03:15.262392Z","shell.execute_reply":"2025-02-26T00:03:15.750741Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Define features and target variable\nfeatures = [\n    'enroll', 'pov', 'iep','ell', 'amind','asian', 'black', 'hisp','multi', 'pac','white'\n]\n\n# The target variable is 'Gap between actual and required spending per-pupil'\ntarget = 'fundinggap'\n\nX = df[features]  # Features\ny = df[target]  # Target\n\n# Split the data into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalize/Standardize the features (optional but recommended for some models)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\n#Training the Model \n# Initialize and train a Decision Tree Regressor\ndt_model = DecisionTreeRegressor(random_state=42)\ndt_model.fit(X_train_scaled, y_train)\n\n# Make predictions on the test set\ny_pred_dt = dt_model.predict(X_test_scaled)\n\n# Evaluate the model's performance\nmse_dt = mean_squared_error(y_test, y_pred_dt)\nr2_dt = r2_score(y_test, y_pred_dt)\n\nprint(f'Decision Tree Model - Mean Squared Error: {mse_dt}')\nprint(f'Decision Tree Model - R-squared: {r2_dt}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:51:54.933148Z","iopub.execute_input":"2025-02-18T17:51:54.933588Z","iopub.status.idle":"2025-02-18T17:51:58.165562Z","shell.execute_reply.started":"2025-02-18T17:51:54.933551Z","shell.execute_reply":"2025-02-18T17:51:58.164278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Option 2: Random Forest\n# Initialize and train a Random Forest Regressor\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train_scaled, y_train)\n\n# Make predictions on the test set\ny_pred_rf = rf_model.predict(X_test_scaled)\n\n# Evaluate the model's performance\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nr2_rf = r2_score(y_test, y_pred_rf)\n\nprint(f'Random Forest Model - Mean Squared Error: {mse_rf}')\nprint(f'Random Forest Model - R-squared: {r2_rf}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T17:52:52.906704Z","iopub.execute_input":"2025-02-18T17:52:52.907137Z","iopub.status.idle":"2025-02-18T17:56:24.912144Z","shell.execute_reply.started":"2025-02-18T17:52:52.907100Z","shell.execute_reply":"2025-02-18T17:56:24.910927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Making predictions on new data \n# Replace 'new_data' with new data for prediction\nnew_data_scaled = scaler.transform(new_data)\npredictions = rf_model.predict(new_data_scaled) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:01:19.300007Z","iopub.execute_input":"2025-02-18T18:01:19.300469Z","iopub.status.idle":"2025-02-18T18:01:19.351672Z","shell.execute_reply.started":"2025-02-18T18:01:19.300431Z","shell.execute_reply":"2025-02-18T18:01:19.349872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the heatmap as a PDF file\nplt.savefig('funding_gaps_heatmap.pdf')  # Save as PDF\nplt.close()  # Close the plot to avoid displaying it again\n\n# Move the PDF file to the output directory for downloading\nshutil.move('funding_gaps_heatmap.pdf', '/kaggle/working/funding_gaps_heatmap.pdf')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:52:02.524545Z","iopub.execute_input":"2024-11-15T04:52:02.525078Z","iopub.status.idle":"2024-11-15T04:52:02.540288Z","shell.execute_reply.started":"2024-11-15T04:52:02.525031Z","shell.execute_reply":"2024-11-15T04:52:02.539071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a variable to filter the dataset by any year of interest\ndf_year = df[df['year'] == 2021]                    # Just like in section 1.3.1, you can use Boleans and comparison opperators to filter\n\n# We specify a size for our figure, and then construct a boxplot. Here we are looking at the\nplt.figure(figsize=(10, 15))                        # You can change the size\nsns.boxplot(data=df_year, x=\"fundinggap\", y=\"stabbr\")     # You can change the values of x and/or y for variables that interest you\n\n# Label our axes and title\nplt.xlabel(\"District funding gap levels\")\nplt.ylabel(\"State\")\nplt.title(\"Funding gap levels by State\")\n\n\n#Print the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:49:37.352021Z","iopub.execute_input":"2024-10-28T04:49:37.352417Z","iopub.status.idle":"2024-10-28T04:49:38.662717Z","shell.execute_reply.started":"2024-10-28T04:49:37.352380Z","shell.execute_reply":"2024-10-28T04:49:38.661518Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter the dataframe for year 2021\ndf_hplot = df[df['year'] == 2021]  # This creates a filtered dataframe\n\n# Create histograms for all numerical columns\ndf_hplot.hist(figsize=(12, 12), bins=20)\n\n# Add title\nplt.suptitle('Distribution of Numerical Variables', fontsize=16)\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:06:47.236977Z","iopub.execute_input":"2024-10-28T05:06:47.237415Z","iopub.status.idle":"2024-10-28T05:06:51.435384Z","shell.execute_reply.started":"2024-10-28T05:06:47.237375Z","shell.execute_reply":"2024-10-28T05:06:51.434128Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder= LabelEncoder()\ndf['RegionCode'] = label_encoder.fit_transform(df['Region'])\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:35:54.444888Z","iopub.execute_input":"2024-10-24T03:35:54.445337Z","iopub.status.idle":"2024-10-24T03:35:54.492511Z","shell.execute_reply.started":"2024-10-24T03:35:54.445301Z","shell.execute_reply":"2024-10-24T03:35:54.491264Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Race_Ethn'] = label_encoder.fit_transform(df['Majority_Group'])\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:52:55.582029Z","iopub.execute_input":"2024-10-24T03:52:55.582509Z","iopub.status.idle":"2024-10-24T03:52:55.632839Z","shell.execute_reply.started":"2024-10-24T03:52:55.582447Z","shell.execute_reply":"2024-10-24T03:52:55.631349Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a count plot for ethnicity over time using Seaborn\nplt.figure(figsize=(12, 6))\nsns.countplot(data=df, x='year', hue='Race_Ethn', palette='viridis')\nplt.title('Distribution of Ethnicity Over Time')\nplt.ylabel('Count')\nplt.xlabel('Year')\nplt.legend(title='Ethnicity')\nplt.xticks(rotation=45)\nplt.tight_layout()  # Adjust layout to prevent clipping\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T04:34:02.815609Z","iopub.execute_input":"2024-11-15T04:34:02.816121Z","iopub.status.idle":"2024-11-15T04:34:03.709330Z","shell.execute_reply.started":"2024-11-15T04:34:02.816077Z","shell.execute_reply":"2024-11-15T04:34:03.707863Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add Region as a facet\nplt.figure(figsize=(12, 6))\ng = sns.FacetGrid(df, col='Region', col_wrap=2, height=4, aspect=1.5)\ng.map_dataframe(sns.countplot, x='year', hue='Race_Ethn', palette='viridis', dodge=True)\ng.add_legend(title='Ethnicity')\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"Year\", \"Count\")\n\n# Adjust layout for better visibility\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:01:58.641750Z","iopub.execute_input":"2024-10-24T04:01:58.642687Z","iopub.status.idle":"2024-10-24T04:02:01.180283Z","shell.execute_reply.started":"2024-10-24T04:01:58.642639Z","shell.execute_reply":"2024-10-24T04:02:01.178910Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#We begin by importing plotly.express as px\nimport plotly.express as px\n\n#Ask Abi about this idea\n# Create an interactive scatter plot\nfig = px.scatter(df,\n                 x=\"ppcstot\",\n                 y=\"RegionCode\",\n                 size=\"enroll\",\n                 size_max=70,\n                 color=\"year\",                  # Both the color and size of the bubblues will reference the total enrollment of each district\n                 hover_name=\"Region\")\n\n\n# Customize and show the plot\nfig.update_layout(title='Interactive Plot')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T22:47:47.868948Z","iopub.execute_input":"2024-10-23T22:47:47.869693Z","iopub.status.idle":"2024-10-23T22:47:48.468922Z","shell.execute_reply.started":"2024-10-23T22:47:47.869650Z","shell.execute_reply":"2024-10-23T22:47:48.467061Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean funding level by state and year\nmean_funding = df.groupby(['state_name', 'year'])['ppcstot'].mean().reset_index()\n\n# Formatting the output nicely\nmean_funding['ppcstot'] = mean_funding['ppcstot'].map('${:,.2f}'.format)  # Formatting as currency\n\n# Display the results\nprint(mean_funding)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:07:27.333156Z","iopub.execute_input":"2024-10-28T05:07:27.334419Z","iopub.status.idle":"2024-10-28T05:07:27.374058Z","shell.execute_reply.started":"2024-10-28T05:07:27.334351Z","shell.execute_reply":"2024-10-28T05:07:27.372945Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\n# 1. Check for normality using Shapiro-Wilk test\nprint(\"\\nShapiro-Wilk Test Results:\")\nfor year in df['year'].unique():\n    stat, p_value = stats.shapiro(df[df['year'] == year]['ppcstot'])\n    print(f\"{year}: Statistic={stat:.3f}, p-value={p_value:.3f}\")\n\n# 2. Check for homogeneity of variances using Levene's test\nprint(\"\\nLevene's Test Results:\")\nstat, p_value = stats.levene(\n    df[df['year'] == '2009']['ppcstot'],\n    df[df['year'] == '2010']['ppcstot'],\n    df[df['year'] == '2011']['ppcstot'],\n    df[df['year'] == '2012']['ppcstot'],\n    df[df['year'] == '2013']['ppcstot'],\n    df[df['year'] == '2014']['ppcstot'],\n    df[df['year'] == '2015']['ppcstot'],\n    df[df['year'] == '2016']['ppcstot'],\n    df[df['year'] == '2017']['ppcstot'],\n    df[df['year'] == '2018']['ppcstot'],\n    df[df['year'] == '2019']['ppcstot'],\n    df[df['year'] == '2020']['ppcstot'],\n    df[df['year'] == '2021']['ppcstot']\n)\nprint(f\"Levene's Test: Statistic={stat:.3f}, p-value={p_value:.3f}\")\n\n# 3. Conduct One-Way ANOVA\nmodel = ols('ppcstot ~ year', data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n# Display the ANOVA results\nprint(\"\\nANOVA Results:\")\nprint(anova_table)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:11:29.801056Z","iopub.execute_input":"2024-10-28T05:11:29.801504Z","iopub.status.idle":"2024-10-28T05:11:31.580808Z","shell.execute_reply.started":"2024-10-28T05:11:29.801461Z","shell.execute_reply":"2024-10-28T05:11:31.576411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.stats import shapiro, levene\n\n# Check normality for each group\nfor state in df['state_name'].unique():\n    stat, p = shapiro(df[df['state_name'] == state]['ppcstot'])\n    print(f'State: {state}, Shapiro-Wilk Stat: {stat:.3f}, p-value: {p:.3f}')\n\n# Check homogeneity of variances\nstat, p = levene(*[df[df['state_name'] == state]['ppcstot'] for state in df['state_name'].unique()])\nprint(f'Levene’s Test Stat: {stat:.3f}, p-value: {p:.3f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:18:43.887252Z","iopub.execute_input":"2024-10-28T05:18:43.888486Z","iopub.status.idle":"2024-10-28T05:18:46.913436Z","shell.execute_reply.started":"2024-10-28T05:18:43.888434Z","shell.execute_reply":"2024-10-28T05:18:46.912159Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:42:58.090674Z","iopub.execute_input":"2024-10-28T05:42:58.091171Z","iopub.status.idle":"2024-10-28T05:42:58.795996Z","shell.execute_reply.started":"2024-10-28T05:42:58.091129Z","shell.execute_reply":"2024-10-28T05:42:58.794824Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select relevant features \nfeatures = df[['ppcstot', 'predcost', 'fundinggap', 'enroll', 'pov', 'iep', 'ell', 'amind', 'asian', 'black', 'hisp', 'multi', 'pac','white']]\n# Scale the features\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(features)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:43:01.566394Z","iopub.execute_input":"2024-10-28T05:43:01.566929Z","iopub.status.idle":"2024-10-28T05:43:01.619969Z","shell.execute_reply.started":"2024-10-28T05:43:01.566886Z","shell.execute_reply":"2024-10-28T05:43:01.618803Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ninertia = []\nK = range(1, 11)\nfor k in K:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(scaled_features)\n    inertia.append(kmeans.inertia_)\n\n# Plot the elbow curve\nplt.figure(figsize=(8, 4))\nplt.plot(K, inertia, marker='o')\nplt.title('Elbow Method for Optimal K')\nplt.xlabel('Number of Clusters (K)')\nplt.ylabel('Inertia')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:43:52.720851Z","iopub.execute_input":"2024-10-28T05:43:52.721309Z","iopub.status.idle":"2024-10-28T05:44:25.486428Z","shell.execute_reply.started":"2024-10-28T05:43:52.721268Z","shell.execute_reply":"2024-10-28T05:44:25.485195Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the K-Means model\noptimal_k = 3  # Replace with the optimal K determined from the elbow plot\nkmeans = KMeans(n_clusters=optimal_k, random_state=42)\nclusters = kmeans.fit_predict(scaled_features)\n\n# Add cluster labels to the original DataFrame\ndf['Cluster'] = clusters","metadata":{"execution":{"iopub.status.busy":"2024-10-28T05:44:59.633011Z","iopub.execute_input":"2024-10-28T05:44:59.634270Z","iopub.status.idle":"2024-10-28T05:45:02.023473Z","shell.execute_reply.started":"2024-10-28T05:44:59.634220Z","shell.execute_reply":"2024-10-28T05:45:02.022160Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(cluster_summary[cluster_summary['Cluster'] == 0])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:12:13.525268Z","iopub.execute_input":"2024-10-28T06:12:13.526586Z","iopub.status.idle":"2024-10-28T06:12:13.537204Z","shell.execute_reply.started":"2024-10-28T06:12:13.526535Z","shell.execute_reply":"2024-10-28T06:12:13.536000Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(cluster_summary[cluster_summary['Cluster'] == 1])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:12:27.426727Z","iopub.execute_input":"2024-10-28T06:12:27.427341Z","iopub.status.idle":"2024-10-28T06:12:27.443380Z","shell.execute_reply.started":"2024-10-28T06:12:27.427280Z","shell.execute_reply":"2024-10-28T06:12:27.441508Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(cluster_summary[cluster_summary['Cluster'] == 2])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:12:41.769245Z","iopub.execute_input":"2024-10-28T06:12:41.769705Z","iopub.status.idle":"2024-10-28T06:12:41.780856Z","shell.execute_reply.started":"2024-10-28T06:12:41.769642Z","shell.execute_reply":"2024-10-28T06:12:41.779662Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Figure out why poverty and ell are not included: # Check the mean values of each feature per cluster\ncluster_summary = df.groupby('Cluster')[scaled_features].mean().reset_index()\nprint(cluster_summary)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:16:42.833663Z","iopub.execute_input":"2024-10-28T06:16:42.834157Z","iopub.status.idle":"2024-10-28T06:16:43.591719Z","shell.execute_reply.started":"2024-10-28T06:16:42.834111Z","shell.execute_reply":"2024-10-28T06:16:43.589877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cluster_summary = df.groupby('Cluster').agg({\n    'fundinggap': 'mean',\n    'enroll': 'mean',\n    'pov': 'mean',\n    'iep': 'mean',\n    'ell': 'mean'\n}).reset_index()\n\nprint(cluster_summary)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:02:20.673481Z","iopub.execute_input":"2024-10-28T06:02:20.674006Z","iopub.status.idle":"2024-10-28T06:02:20.703634Z","shell.execute_reply.started":"2024-10-28T06:02:20.673955Z","shell.execute_reply":"2024-10-28T06:02:20.702195Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\n\n# Scatter plot to visualize clusters\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=df, x='fundinggap', y='pov', hue='Cluster', palette='viridis')\nplt.title('K-means Clustering of School Districts, all years')\nplt.xlabel('Funding Gap')\nplt.ylabel('Percentage of Students in Poverty')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:03:45.929368Z","iopub.execute_input":"2024-10-28T06:03:45.929877Z","iopub.status.idle":"2024-10-28T06:03:56.678792Z","shell.execute_reply.started":"2024-10-28T06:03:45.929832Z","shell.execute_reply":"2024-10-28T06:03:56.677718Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cluster_summary = df.groupby('Cluster').agg({\n    'fundinggap': 'mean',\n    'amind': 'mean',\n    'asian': 'mean',\n    'black': 'mean',    \n    'hisp': 'mean',\n    'multi': 'mean',\n    'pac': 'mean',\n    'white': 'mean'\n}).reset_index()\n\nprint(cluster_summary)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:07:09.019332Z","iopub.execute_input":"2024-10-28T06:07:09.019792Z","iopub.status.idle":"2024-10-28T06:07:09.076152Z","shell.execute_reply.started":"2024-10-28T06:07:09.019748Z","shell.execute_reply":"2024-10-28T06:07:09.074720Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\n\n# Scatter plot to visualize clusters\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=df, x='fundinggap', y='hisp', hue='Cluster', palette='viridis')\nplt.title('K-means Clustering of School Districts, all years')\nplt.xlabel('Funding Gap')\nplt.ylabel('Percentage of Hispanic Students')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T06:07:49.058162Z","iopub.execute_input":"2024-10-28T06:07:49.058990Z","iopub.status.idle":"2024-10-28T06:07:59.709062Z","shell.execute_reply.started":"2024-10-28T06:07:49.058920Z","shell.execute_reply":"2024-10-28T06:07:59.707666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the clusters (using two features for visualization)\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=df['ppcstot'], y=df['fundinggap'], hue=df['cluster'], palette='viridis', s=100)\nplt.title('K-Means Clustering')\nplt.xlabel('Actual Spending')\nplt.ylabel('Funding Gap')\nplt.legend(title='Cluster')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:43:31.976284Z","iopub.execute_input":"2024-10-24T03:43:31.977158Z","iopub.status.idle":"2024-10-24T03:43:40.909530Z","shell.execute_reply.started":"2024-10-24T03:43:31.977109Z","shell.execute_reply":"2024-10-24T03:43:40.908235Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Explore this idea with Abi\n# Plotting the clusters (using two features for visualization)\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=df['Race_Ethn'], y=df['fundinggap'], hue=df['cluster'], palette='viridis', s=100)\nplt.title('K-Means Clustering')\nplt.xlabel('Race_Ethn')\nplt.ylabel('Funding Gap')\nplt.legend(title='Cluster')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:05:38.459138Z","iopub.execute_input":"2024-10-24T04:05:38.459835Z","iopub.status.idle":"2024-10-24T04:05:47.120754Z","shell.execute_reply.started":"2024-10-24T04:05:38.459788Z","shell.execute_reply":"2024-10-24T04:05:47.119567Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Explore this idea with Abi\n# Visualize Funding Gap vs. Percentage of Minority Students\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x='year', y='fundinggap', label='Funding Gap', marker='o')\nsns.lineplot(data=df, x='year', y='black', label='Black students', marker='s')\nplt.title('Funding Gaps and Black students Over Time')\nplt.ylabel('Funding Gap / Black students')\nplt.xlabel('Year')\nplt.legend()\nplt.grid()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:10:30.744775Z","iopub.execute_input":"2024-10-24T04:10:30.745600Z","iopub.status.idle":"2024-10-24T04:10:34.032006Z","shell.execute_reply.started":"2024-10-24T04:10:30.745535Z","shell.execute_reply":"2024-10-24T04:10:34.030707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_optimal_clusters(scaled_features, max_clusters=6):\n    \"\"\"\n    Find the optimal number of clusters using the elbow method and silhouette score.\n    \n    Parameters:\n    scaled_features (numpy.array): Scaled feature array\n    max_clusters (int): Maximum number of clusters to try\n    \n    Returns:\n    tuple: (inertias, silhouette_scores)\n    \"\"\"\n    inertias = []\n    silhouette_scores = []\n    \n    for k in range(2, max_clusters + 1):\n        kmeans = KMeans(n_clusters=k, random_state=42)\n        kmeans.fit(scaled_features)\n        inertias.append(kmeans.inertia_)\n        silhouette_scores.append(silhouette_score(scaled_features, kmeans.labels_))\n        \n    return inertias, silhouette_scores","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:44:40.595510Z","iopub.execute_input":"2024-10-24T03:44:40.595980Z","iopub.status.idle":"2024-10-24T03:44:40.605155Z","shell.execute_reply.started":"2024-10-24T03:44:40.595937Z","shell.execute_reply":"2024-10-24T03:44:40.603356Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_clustering_metrics(inertias, silhouette_scores):\n    \"\"\"\n    Plot the elbow curve and silhouette scores.\n    \n    Parameters:\n    inertias (list): List of inertia values\n    silhouette_scores (list): List of silhouette scores\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # Plot elbow curve\n    ax1.plot(range(2, len(inertias) + 2), inertias, marker='o')\n    ax1.set_xlabel('Number of clusters (k)')\n    ax1.set_ylabel('Inertia')\n    ax1.set_title('Elbow Method')\n    \n    # Plot silhouette scores\n    ax2.plot(range(2, len(silhouette_scores) + 2), silhouette_scores, marker='o')\n    ax2.set_xlabel('Number of clusters (k)')\n    ax2.set_ylabel('Silhouette Score')\n    ax2.set_title('Silhouette Analysis')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:44:47.101926Z","iopub.execute_input":"2024-10-24T03:44:47.103209Z","iopub.status.idle":"2024-10-24T03:44:47.111174Z","shell.execute_reply.started":"2024-10-24T03:44:47.103142Z","shell.execute_reply":"2024-10-24T03:44:47.109852Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def perform_clustering(scaled_features, n_clusters):\n    \"\"\"\n    Perform K-means clustering with the specified number of clusters.\n    \n    Parameters:\n    scaled_features (numpy.array): Scaled feature array\n    n_clusters (int): Number of clusters to create\n    \n    Returns:\n    tuple: (KMeans model, cluster labels)\n    \"\"\"\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    labels = kmeans.fit_predict(scaled_features)\n    return kmeans, labels\n\ndef analyze_clusters(df, feature_columns, labels, scaler):\n    \"\"\"\n    Analyze the characteristics of each cluster.\n    \n    Parameters:\n    df (pandas.DataFrame): Original dataframe\n    feature_columns (list): List of feature columns used\n    labels (numpy.array): Cluster labels\n    scaler (StandardScaler): Fitted scaler object\n    \n    Returns:\n    pandas.DataFrame: Cluster analysis results\n    \"\"\"\n    # Add cluster labels to the original dataframe\n    df_with_clusters = df.copy()\n    df_with_clusters['Cluster'] = labels\n    \n    # Calculate cluster means\n    cluster_means = df_with_clusters.groupby('Cluster')[feature_columns].mean()\n    \n    # Calculate cluster sizes\n    cluster_sizes = df_with_clusters['Cluster'].value_counts().sort_index()\n    \n    return cluster_means, cluster_sizes\n\ndef plot_cluster_characteristics(cluster_means, feature_columns):\n    \"\"\"\n    Create a heatmap of cluster characteristics.\n    \n    Parameters:\n    cluster_means (pandas.DataFrame): Mean values for each cluster\n    feature_columns (list): List of feature columns used\n    \"\"\"\n    plt.figure(figsize=(12, 8))\n    sns.heatmap(cluster_means, cmap='RdYlBu', center=0, annot=True, fmt='.2f')\n    plt.title('Cluster Characteristics Heatmap')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:45:06.047901Z","iopub.execute_input":"2024-10-24T03:45:06.048350Z","iopub.status.idle":"2024-10-24T03:45:06.058970Z","shell.execute_reply.started":"2024-10-24T03:45:06.048308Z","shell.execute_reply":"2024-10-24T03:45:06.057649Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# View all data points in cluster 0\ncluster_0 = df[df['cluster'] == 0]\nprint(cluster_0)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:45:14.129998Z","iopub.execute_input":"2024-10-24T03:45:14.130445Z","iopub.status.idle":"2024-10-24T03:45:14.160231Z","shell.execute_reply.started":"2024-10-24T03:45:14.130404Z","shell.execute_reply":"2024-10-24T03:45:14.158958Z"},"trusted":true},"outputs":[],"execution_count":null}]}